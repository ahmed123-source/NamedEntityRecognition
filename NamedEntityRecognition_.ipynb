{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_eZ6Xzs5mrg",
        "outputId": "bbad2b1d-73e0-46e5-d9f3-7bf8d7e77047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebastian Thrun PERSON\n",
            "2007 DATE\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "from spacy.pipeline import EntityRuler\n",
        "import json\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "PMm49Vzo5xaP",
        "outputId": "7771002d-9daf-4d1d-deec-2bfc499d8563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">When \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sebastian Thrun\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " started working on self-driving cars at Google in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2007\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", few people outside of the company took him seriously.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATA = [('The F15 aircraft uses a lot of fuel', {'entities': [(4, 7, 'aircraft')]}),\n",
        " ('did you see the F16 landing?', {'entities': [(16, 19, 'aircraft')]}),\n",
        " ('how many missiles can a F35 carry', {'entities': [(24, 27, 'aircraft')]}),\n",
        " ('is the F15 outdated', {'entities': [(7, 10, 'aircraft')]}),\n",
        " ('does the US still train pilots to dog fight?',\n",
        "  {'entities': [(0, 0, 'aircraft')]}),\n",
        " ('how long does it take to train a F16 pilot',\n",
        "  {'entities': [(33, 36, 'aircraft')]}),\n",
        " ('how much does a F35 cost', {'entities': [(16, 19, 'aircraft')]}),\n",
        " ('would it be possible to steal a F15', {'entities': [(32, 35, 'aircraft')]}),\n",
        " ('who manufactures the F16', {'entities': [(21, 24, 'aircraft')]}),\n",
        " ('how many countries have bought the F35',\n",
        "  {'entities': [(35, 38, 'aircraft')]}),\n",
        " ('is the F35 a waste of money', {'entities': [(7, 10, 'aircraft')]})]\n",
        " #train_data=[(text,{\"entities\":[(start_char,end_char,label)]}\n",
        " #table entity : entity ->id_intent ManytoOne\n"
      ],
      "metadata": {
        "id": "G0aUxm5KNuJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conversion to .spacy format\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "#nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\") # load other spacy model\n",
        "\n",
        "db = DocBin() # create a DocBin object\n",
        "\n",
        "for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
        "    doc = nlp.make_doc(text) # create doc object from text\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents # label the text with the ents\n",
        "    db.add(doc)\n",
        "db.to_disk(\"./train.spacy\") # save the docbin object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0qUhFLdNvwf",
        "outputId": "bbedccdd-e1df-43c3-8c19-fc828161cc90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:00<00:00, 1310.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping entity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#génération du train_data sous le format suivant: [(text,{\"entities\":[(start_char,end_char,label)]}\n",
        "train_data = []\n",
        "nlp = English()\n",
        "patterns = [{\"label\":\"fruit\",\"pattern\":\"orange\"},{\"label\":\"vegetable\",\"pattern\":\"pepper\"}]\n",
        "ruler = nlp.add_pipe(\"entity_ruler\")\n",
        "ruler.add_patterns(patterns)\n",
        "doc=nlp(\"i have eaten an orange and a pepper\")\n",
        "entities=[]\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)\n",
        "    entities.append((entity.start_char,entity.end_char,entity.label_))\n",
        "train_data.append((\"i have eaten an orange and a pepper\",{'entities':entities}))\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmOHhdpooAqU",
        "outputId": "d4801714-86f0-49c7-85c8-19ce115a7338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "orange fruit\n",
            "pepper vegetable\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i have eaten an orange and a pepper',\n",
              "  {'entities': [(16, 22, 'fruit'), (29, 35, 'vegetable')]})]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsaZ9VjgqLjb",
        "outputId": "e09cbcd2-d2dd-477c-f21a-80ef21d3e84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy\n",
        "#trainning  model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgZ6GJz29jtP",
        "outputId": "dfb0e70a-3c13-4fd3-dbe4-9d3bdcd70e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-22 13:06:09,695] [INFO] Set up nlp object from config\n",
            "[2022-07-22 13:06:09,713] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2022-07-22 13:06:09,718] [INFO] Created vocabulary\n",
            "[2022-07-22 13:06:10,350] [WARNING] [W112] The model specified to use for initial vectors (en_core_web_sm) has no vectors. This is almost certainly a mistake.\n",
            "[2022-07-22 13:06:10,353] [INFO] Added vectors: en_core_web_sm\n",
            "[2022-07-22 13:06:10,354] [INFO] Finished initializing nlp object\n",
            "[2022-07-22 13:06:10,636] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     41.50    0.00    0.00    0.00    0.00\n",
            "200     200          0.16    280.65  100.00  100.00  100.00    1.00\n",
            "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp1 = spacy.load(r\"./output/model-best\") #load the best model"
      ],
      "metadata": {
        "id": "EJHrMn9PA-Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp1(\"is A36 is bought by tunisia \")"
      ],
      "metadata": {
        "id": "wnrrth0hDHNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Uf_udmNtEHVe",
        "outputId": "4197a53d-9c47-405f-91df-30f687a4affc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">is \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F36\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">aircraft</span>\n",
              "</mark>\n",
              " is bought by tunisia </div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}